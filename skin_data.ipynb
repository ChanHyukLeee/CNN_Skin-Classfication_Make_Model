{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skin_data.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JustCal1MeLee/cnn_skin-classfication_makemodel_practice/blob/main/skin_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdTtDt0tzYMs"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1ALMfnL5xpP"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import numpy as np\n",
        "# import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# import os "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoFJYaiI7lMH"
      },
      "source": [
        "learning_rate = 0.01\n",
        "traing_epoch = 3\n",
        "batch_size = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5aiIHiL6wsZ"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_rPn0sr7J-V"
      },
      "source": [
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bfwYpqVJciE"
      },
      "source": [
        "database_path = '/content/drive/MyDrive/DATABASE'\n",
        "# the database folder have a classification label folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a7xPN9m_3yf"
      },
      "source": [
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "trans = transforms.Compose([\n",
        "                            transforms.Resize([300,300]),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.RandomHorizontalFlip(p=0.5),\n",
        "                            transforms.RandomVerticalFlip(p=0.5),  \n",
        "                            transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
        "])\n",
        "# 데이터늘리기위해 randomhorizontalflip , verticalflip 활용 \n",
        "train_data = torchvision.datasets.ImageFolder(root = database_path, transform = trans)\n",
        "test_data = torchvision.datasets.ImageFolder(root = database_path, transform= trans)\n",
        "# imagefolder 함수 이용시 편하게 label활용가능"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLjFFtKBxU83"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j35BoV9YxiS2"
      },
      "source": [
        "print(train_data.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sgUo8-YvoUx"
      },
      "source": [
        "# 알맞게 됐나 확인\n",
        "def show_transformed_images(dataset):\n",
        "    loader = DataLoader(dataset, batch_size= 6, shuffle = True)\n",
        "    batch = next(iter(loader))\n",
        "    images, labels = batch\n",
        "\n",
        "    grid = torchvision.utils.make_grid(images, nrow= 3)\n",
        "    plt.figure(figsize=(11,11))\n",
        "    plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "    print('labels :', labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYLsE_b6wh64"
      },
      "source": [
        "show_transformed_images(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkJVY1TIBCQC"
      },
      "source": [
        "train_loader = DataLoader(train_data , batch_size=batch_size, shuffle= True, \n",
        "                             drop_last=True)\n",
        "test_loader = DataLoader(test_data , batch_size=batch_size, shuffle=True, \n",
        "                             drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBk3Siqh32ER"
      },
      "source": [
        "def train_nn(model, train_loader, test_loader, criterion, optimizer, n_epochs):\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch number %d\" % (epoch+1))\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0.0\n",
        "        total = 0\n",
        "        \n",
        "        for data in train_loader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            total += labels.size(0)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            running_correct += (labels == predicted).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss/len(train_loader)\n",
        "        epoch_acc = 100.00 * running_correct / total\n",
        "\n",
        "        print( \" -training dataset, Got %d out of %d images correctly (%.3f%%), Epoch loss : %.3f\" \n",
        "              %(running_correct, total, epoch_acc, epoch_loss))\n",
        "        evaluate_model_on_test_set(model, test_loader)\n",
        "\n",
        "    print(\"finished\")\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zD0LOX668Qg"
      },
      "source": [
        "def evaluate_model_on_test_set(model, test_loader):\n",
        "    model.eval()\n",
        "    predicted_correctly_on_epoch = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            total += labels.size(0)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            predicted_correctly_on_epoch += (predicted == labels).sum().item()\n",
        "    epoch_acc = 100.0 * predicted_correctly_on_epoch / total\n",
        "    print( \" -Testing dataset, Got %d out of %d images correctly (%.3f%%)\" \n",
        "              %(predicted_correctly_on_epoch, total, epoch_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDyyXCIaXDSy"
      },
      "source": [
        "resnet18_model = torchvision.models.resnet18(pretrained=True)\n",
        "num_features = resnet18_model.fc.in_features\n",
        "number_of_classes = 4\n",
        "resnet18_model.fc = nn.Linear(num_features, number_of_classes)\n",
        "resnet18_model = resnet18_model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(resnet18_model.parameters(), lr = learning_rate, momentum= 0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lok7hV-82re"
      },
      "source": [
        "train_nn(resnet18_model, train_loader, test_loader, loss_fn, optimizer, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q58uo7LzDUi2"
      },
      "source": [
        "# save model\n",
        "model_path = '/content/drive/MyDrive/model/model.pt'\n",
        "torch.save(resnet18_model.state_dict(), model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FfeD88qOMv8"
      },
      "source": [
        "https://stackoverflow.com/questions/53612835/size-mismatch-for-fc-bias-and-fc-weight-in-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHtowS8pFNrK"
      },
      "source": [
        "# if loaded\n",
        "model_path ='/content/drive/MyDrive/model/model.pt'\n",
        "model = torchvision.models.resnet18(pretrained = True)\n",
        "num_features = model.fc.in_features\n",
        "number_of_classes = 4\n",
        "model.fc = nn.Linear(num_features, number_of_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}